package tools

import (
	"context"
	"fmt"
	"sort"
	"sync"

	"github.com/aiplusall/aiplusall-kb/internal/types"
	"github.com/aiplusall/aiplusall-kb/internal/types/interfaces"
)

// QueryKnowledgeGraphTool queries the knowledge graph for entities and relationships
type QueryKnowledgeGraphTool struct {
	BaseTool
	knowledgeService interfaces.KnowledgeBaseService
}

// NewQueryKnowledgeGraphTool creates a new query knowledge graph tool
func NewQueryKnowledgeGraphTool(knowledgeService interfaces.KnowledgeBaseService) *QueryKnowledgeGraphTool {
	description := `Query knowledge graph to explore entity relationships and knowledge networks.

## Core Function
Explores relationships between entities in knowledge bases that have graph extraction configured.

## When to Use
âœ… **Use for**:
- Understanding relationships between entities (e.g., "relationship between Docker and Kubernetes")
- Exploring knowledge networks and concept associations
- Finding related information about specific entities
- Understanding technical architecture and system relationships

âŒ **Don't use for**:
- General text search â†’ use knowledge_search
- Knowledge base without graph extraction configured
- Need exact document content â†’ use knowledge_search

## Parameters
- **knowledge_base_ids** (required): Array of knowledge base IDs (1-10). Only KBs with graph extraction configured will be effective.
- **query** (required): Query content - can be entity name, relationship query, or concept search.

## Graph Configuration
Knowledge graph must be pre-configured in knowledge bases:
- **Entity types** (Nodes): e.g., "Technology", "Tool", "Concept"
- **Relationship types** (Relations): e.g., "depends_on", "uses", "contains"

If KB is not configured with graph, tool will return regular search results.

## Workflow
1. **Relationship exploration**: query_knowledge_graph â†’ list_knowledge_chunks (for detailed content)
2. **Network analysis**: query_knowledge_graph â†’ knowledge_search (for comprehensive understanding)
3. **Topic research**: knowledge_search â†’ query_knowledge_graph (for deep entity relationships)

## Notes
- Results indicate graph configuration status
- Cross-KB results are automatically deduplicated
- Results are sorted by relevance`

	return &QueryKnowledgeGraphTool{
		BaseTool:         NewBaseTool("query_knowledge_graph", description),
		knowledgeService: knowledgeService,
	}
}

// Parameters returns the JSON schema for the tool's parameters
func (t *QueryKnowledgeGraphTool) Parameters() map[string]interface{} {
	return map[string]interface{}{
		"type": "object",
		"properties": map[string]interface{}{
			"knowledge_base_ids": map[string]interface{}{
				"type":        "array",
				"description": "Array of knowledge base IDs to query",
				"items": map[string]interface{}{
					"type": "string",
				},
				"minItems": 1,
				"maxItems": 10,
			},
			"query": map[string]interface{}{
				"type":        "string",
				"description": "æŸ¥è¯¢å†…å®¹ï¼ˆå®ä½“åç§°æˆ–æŸ¥è¯¢æ–‡æœ¬ï¼‰",
			},
		},
		"required": []string{"knowledge_base_ids", "query"},
	}
}

// Execute performs the knowledge graph query with concurrent KB processing
func (t *QueryKnowledgeGraphTool) Execute(ctx context.Context, args map[string]interface{}) (*types.ToolResult, error) {
	// Extract knowledge_base_ids array
	kbIDsRaw, ok := args["knowledge_base_ids"].([]interface{})
	if !ok || len(kbIDsRaw) == 0 {
		return &types.ToolResult{
			Success: false,
			Error:   "knowledge_base_ids is required and must be a non-empty array",
		}, fmt.Errorf("knowledge_base_ids is required")
	}

	// Convert to string slice
	var kbIDs []string
	for _, id := range kbIDsRaw {
		if idStr, ok := id.(string); ok && idStr != "" {
			kbIDs = append(kbIDs, idStr)
		}
	}

	if len(kbIDs) == 0 {
		return &types.ToolResult{
			Success: false,
			Error:   "knowledge_base_ids must contain at least one valid KB ID",
		}, fmt.Errorf("no valid KB IDs provided")
	}

	query, ok := args["query"].(string)
	if !ok || query == "" {
		return &types.ToolResult{
			Success: false,
			Error:   "query is required",
		}, fmt.Errorf("invalid query")
	}

	// Concurrently query all knowledge bases
	type graphQueryResult struct {
		kbID    string
		kb      *types.KnowledgeBase
		results []*types.SearchResult
		err     error
	}

	var wg sync.WaitGroup
	var mu sync.Mutex
	kbResults := make(map[string]*graphQueryResult)

	searchParams := types.SearchParams{
		QueryText:  query,
		MatchCount: 10,
	}

	for _, kbID := range kbIDs {
		wg.Add(1)
		go func(id string) {
			defer wg.Done()

			// Get knowledge base to check graph configuration
			kb, err := t.knowledgeService.GetKnowledgeBaseByID(ctx, id)
			if err != nil {
				mu.Lock()
				kbResults[id] = &graphQueryResult{kbID: id, err: fmt.Errorf("è·å–çŸ¥è¯†åº“å¤±è´¥: %v", err)}
				mu.Unlock()
				return
			}

			// Check if graph extraction is enabled
			if kb.ExtractConfig == nil || (len(kb.ExtractConfig.Nodes) == 0 && len(kb.ExtractConfig.Relations) == 0) {
				mu.Lock()
				kbResults[id] = &graphQueryResult{kbID: id, err: fmt.Errorf("æœªé…ç½®çŸ¥è¯†å›¾è°±æŠ½å–")}
				mu.Unlock()
				return
			}

			// Query graph
			results, err := t.knowledgeService.HybridSearch(ctx, id, searchParams)
			if err != nil {
				mu.Lock()
				kbResults[id] = &graphQueryResult{kbID: id, kb: kb, err: fmt.Errorf("æŸ¥è¯¢å¤±è´¥: %v", err)}
				mu.Unlock()
				return
			}

			mu.Lock()
			kbResults[id] = &graphQueryResult{kbID: id, kb: kb, results: results}
			mu.Unlock()
		}(kbID)
	}

	wg.Wait()

	// Collect and deduplicate results
	seenChunks := make(map[string]*types.SearchResult)
	var errors []string
	graphConfigs := make(map[string]map[string]interface{})
	kbCounts := make(map[string]int)

	for _, kbID := range kbIDs {
		result := kbResults[kbID]
		if result.err != nil {
			errors = append(errors, fmt.Sprintf("KB %s: %v", kbID, result.err))
			continue
		}

		if result.kb != nil && result.kb.ExtractConfig != nil {
			graphConfigs[kbID] = map[string]interface{}{
				"nodes":     result.kb.ExtractConfig.Nodes,
				"relations": result.kb.ExtractConfig.Relations,
			}
		}

		kbCounts[kbID] = len(result.results)
		for _, r := range result.results {
			if _, seen := seenChunks[r.ID]; !seen {
				seenChunks[r.ID] = r
			}
		}
	}

	// Convert map to slice and sort by score
	allResults := make([]*types.SearchResult, 0, len(seenChunks))
	for _, result := range seenChunks {
		allResults = append(allResults, result)
	}

	sort.Slice(allResults, func(i, j int) bool {
		return allResults[i].Score > allResults[j].Score
	})

	if len(allResults) == 0 {
		return &types.ToolResult{
			Success: true,
			Output:  "æœªæ‰¾åˆ°ç›¸å…³çš„å›¾è°±ä¿¡æ¯ã€‚",
			Data: map[string]interface{}{
				"knowledge_base_ids": kbIDs,
				"query":              query,
				"results":            []interface{}{},
				"graph_configs":      graphConfigs,
				"errors":             errors,
			},
		}, nil
	}

	// Format output with enhanced graph information
	output := "=== çŸ¥è¯†å›¾è°±æŸ¥è¯¢ ===\n\n"
	output += fmt.Sprintf("ğŸ“Š æŸ¥è¯¢: %s\n", query)
	output += fmt.Sprintf("ğŸ¯ ç›®æ ‡çŸ¥è¯†åº“: %v\n", kbIDs)
	output += fmt.Sprintf("âœ“ æ‰¾åˆ° %d æ¡ç›¸å…³ç»“æœï¼ˆå·²å»é‡ï¼‰\n\n", len(allResults))

	if len(errors) > 0 {
		output += "=== âš ï¸ éƒ¨åˆ†å¤±è´¥ ===\n"
		for _, errMsg := range errors {
			output += fmt.Sprintf("  - %s\n", errMsg)
		}
		output += "\n"
	}

	// Display graph configuration status
	hasGraphConfig := false
	output += "=== ğŸ“ˆ å›¾è°±é…ç½®çŠ¶æ€ ===\n\n"
	for kbID, config := range graphConfigs {
		hasGraphConfig = true
		output += fmt.Sprintf("çŸ¥è¯†åº“ã€%sã€‘:\n", kbID)

		nodes, _ := config["nodes"].([]interface{})
		relations, _ := config["relations"].([]interface{})

		if len(nodes) > 0 {
			output += fmt.Sprintf("  âœ“ å®ä½“ç±»å‹ (%d): ", len(nodes))
			nodeNames := make([]string, 0, len(nodes))
			for _, n := range nodes {
				if nodeMap, ok := n.(map[string]interface{}); ok {
					if name, ok := nodeMap["name"].(string); ok {
						nodeNames = append(nodeNames, name)
					}
				}
			}
			output += fmt.Sprintf("%v\n", nodeNames)
		} else {
			output += "  âš ï¸ æœªé…ç½®å®ä½“ç±»å‹\n"
		}

		if len(relations) > 0 {
			output += fmt.Sprintf("  âœ“ å…³ç³»ç±»å‹ (%d): ", len(relations))
			relNames := make([]string, 0, len(relations))
			for _, r := range relations {
				if relMap, ok := r.(map[string]interface{}); ok {
					if name, ok := relMap["name"].(string); ok {
						relNames = append(relNames, name)
					}
				}
			}
			output += fmt.Sprintf("%v\n", relNames)
		} else {
			output += "  âš ï¸ æœªé…ç½®å…³ç³»ç±»å‹\n"
		}
		output += "\n"
	}

	if !hasGraphConfig {
		output += "âš ï¸ æ‰€æŸ¥è¯¢çš„çŸ¥è¯†åº“å‡æœªé…ç½®å›¾è°±æŠ½å–\n"
		output += "ğŸ’¡ æç¤º: éœ€è¦åœ¨çŸ¥è¯†åº“è®¾ç½®ä¸­é…ç½®å®ä½“å’Œå…³ç³»ç±»å‹\n\n"
	}

	// Display result counts by KB
	if len(kbCounts) > 0 {
		output += "=== ğŸ“š çŸ¥è¯†åº“è¦†ç›– ===\n"
		for kbID, count := range kbCounts {
			output += fmt.Sprintf("  - %s: %d æ¡ç»“æœ\n", kbID, count)
		}
		output += "\n"
	}

	// Display search results
	output += "=== ğŸ” æŸ¥è¯¢ç»“æœ ===\n\n"
	if !hasGraphConfig {
		output += "ğŸ’¡ å½“å‰è¿”å›ç›¸å…³æ–‡æ¡£ç‰‡æ®µï¼ˆçŸ¥è¯†åº“æœªé…ç½®å›¾è°±ï¼‰\n\n"
	} else {
		output += "ğŸ’¡ åŸºäºå›¾è°±é…ç½®çš„ç›¸å…³å†…å®¹æ£€ç´¢\n\n"
	}

	formattedResults := make([]map[string]interface{}, 0, len(allResults))
	currentKB := ""

	for i, result := range allResults {
		// Group by knowledge base
		if result.KnowledgeID != currentKB {
			currentKB = result.KnowledgeID
			if i > 0 {
				output += "\n"
			}
			output += fmt.Sprintf("ã€æ¥æºæ–‡æ¡£: %sã€‘\n\n", result.KnowledgeTitle)
		}

		relevanceLevel := GetRelevanceLevel(result.Score)

		output += fmt.Sprintf("ç»“æœ #%d:\n", i+1)
		output += fmt.Sprintf("  ğŸ“ ç›¸å…³åº¦: %.2f (%s)\n", result.Score, relevanceLevel)
		output += fmt.Sprintf("  ğŸ”— åŒ¹é…æ–¹å¼: %s\n", FormatMatchType(result.MatchType))
		output += fmt.Sprintf("  ğŸ“„ å†…å®¹: %s\n", result.Content)
		output += fmt.Sprintf("  ğŸ†” chunk_id: %s\n\n", result.ID)

		formattedResults = append(formattedResults, map[string]interface{}{
			"result_index":    i + 1,
			"chunk_id":        result.ID,
			"content":         result.Content,
			"score":           result.Score,
			"relevance_level": relevanceLevel,
			"knowledge_id":    result.KnowledgeID,
			"knowledge_title": result.KnowledgeTitle,
			"match_type":      FormatMatchType(result.MatchType),
		})
	}

	output += "=== ğŸ’¡ ä½¿ç”¨æç¤º ===\n"
	output += "- âœ“ ç»“æœå·²è·¨çŸ¥è¯†åº“å»é‡å¹¶æŒ‰ç›¸å…³åº¦æ’åº\n"
	output += "- âœ“ ä½¿ç”¨ get_chunk_detail è·å–å®Œæ•´å†…å®¹\n"
	output += "- âœ“ ä½¿ç”¨ list_knowledge_chunks æ¢ç´¢ä¸Šä¸‹æ–‡\n"
	if !hasGraphConfig {
		output += "- âš ï¸ é…ç½®å›¾è°±æŠ½å–ä»¥è·å¾—æ›´ç²¾å‡†çš„å®ä½“å…³ç³»ç»“æœ\n"
	}
	output += "- â³ å®Œæ•´çš„å›¾æŸ¥è¯¢è¯­è¨€ï¼ˆCypherï¼‰æ”¯æŒå¼€å‘ä¸­\n"

	// Build structured graph data for frontend visualization
	graphData := buildGraphVisualizationData(allResults, graphConfigs)

	return &types.ToolResult{
		Success: true,
		Output:  output,
		Data: map[string]interface{}{
			"knowledge_base_ids": kbIDs,
			"query":              query,
			"results":            formattedResults,
			"count":              len(allResults),
			"kb_counts":          kbCounts,
			"graph_configs":      graphConfigs,
			"graph_data":         graphData,
			"has_graph_config":   hasGraphConfig,
			"errors":             errors,
			"display_type":       "graph_query_results",
		},
	}, nil
}

// buildGraphVisualizationData builds structured data for graph visualization
func buildGraphVisualizationData(
	results []*types.SearchResult,
	graphConfigs map[string]map[string]interface{},
) map[string]interface{} {
	// Build a simple graph structure for frontend visualization
	nodes := make([]map[string]interface{}, 0)
	edges := make([]map[string]interface{}, 0)

	// Create nodes from results
	seenEntities := make(map[string]bool)
	for i, result := range results {
		if !seenEntities[result.ID] {
			nodes = append(nodes, map[string]interface{}{
				"id":       result.ID,
				"label":    fmt.Sprintf("Chunk %d", i+1),
				"content":  result.Content,
				"kb_id":    result.KnowledgeID,
				"kb_title": result.KnowledgeTitle,
				"score":    result.Score,
				"type":     "chunk",
			})
			seenEntities[result.ID] = true
		}
	}

	return map[string]interface{}{
		"nodes":       nodes,
		"edges":       edges,
		"total_nodes": len(nodes),
		"total_edges": len(edges),
	}
}
