# 知识图谱批量重建功能使用说明

## 功能概述

知识图谱批量重建功能允许你对已有知识库进行批量图谱提取和重建。这对于以下场景特别有用：

1. **后期启用图谱**: 知识库创建时没有启用图谱提取，后期希望补充构建图谱
2. **配置更新**: 修改了图谱提取配置（如关系类型、实体类型），希望重新提取
3. **图谱优化**: 使用GraphBuilder的全局优化算法（权重计算、度数分析）重建图谱
4. **故障恢复**: 图谱数据损坏或丢失，需要从原始文档重建

## 技术架构

### 两种图谱构建方式对比

| 特性 | ChunkExtractService (增量式) | GraphBuilder (批量式) |
|------|---------------------------|---------------------|
| **触发时机** | 文档上传时自动触发 | 手动API调用触发 |
| **处理方式** | 逐chunk异步处理 | 批量全局处理 |
| **配置来源** | `extract.extract_graph` | `conversation.summary` prompts |
| **提取阶段** | 一次性提取实体+关系 | 两阶段（先实体，再关系） |
| **全局优化** | ❌ 无 | ✅ 权重计算、度数分析、chunk关系网络 |
| **适用场景** | 实时增量更新 | 批量重建、全局优化 |
| **当前状态** | ✅ 已启用 | ✅ 已实现（本功能） |

### 实现原理

批量重建功能基于已实现的`GraphBuilder`构建，完整流程如下：

```
用户调用API
    ↓
创建异步任务 (TypeGraphRebuild)
    ↓
GraphRebuildService.Handle
    ↓
1. 获取知识库配置验证
2. 获取所有knowledge和chunks
3. 删除旧图谱数据
4. 分批调用GraphBuilder.BuildGraph
    ├─ extractEntities (提取实体)
    ├─ extractRelationships (提取关系)
    ├─ calculateWeights (计算权重)
    ├─ calculateDegrees (计算度数)
    └─ buildChunkGraph (构建chunk关系网络)
5. 完成并记录日志
```

## API使用方法

### 端点信息

```
POST /api/v1/knowledge-bases/{id}/rebuild-graph
```

### 请求参数

**路径参数:**
- `id`: 知识库ID (必需)

**请求体 (JSON):**
```json
{
  "model_id": "string",    // 可选，使用的模型ID，留空则使用知识库默认模型
  "batch_size": 100        // 可选，批处理大小，0表示全量处理
}
```

### 请求示例

#### 使用curl

```bash
# 使用默认模型全量重建
curl -X POST "http://localhost:8080/api/v1/knowledge-bases/kb-00000001/rebuild-graph" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "batch_size": 0
  }'

# 指定模型和批次大小
curl -X POST "http://localhost:8080/api/v1/knowledge-bases/kb-00000001/rebuild-graph" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "model_id": "model-uuid-here",
    "batch_size": 100
  }'
```

#### 使用Python

```python
import requests

url = "http://localhost:8080/api/v1/knowledge-bases/kb-00000001/rebuild-graph"
headers = {
    "Content-Type": "application/json",
    "Authorization": "Bearer YOUR_TOKEN"
}
payload = {
    "model_id": "model-uuid-here",  # 可选
    "batch_size": 100                # 0表示全量处理
}

response = requests.post(url, json=payload, headers=headers)
print(response.json())
```

### 响应示例

**成功响应 (200 OK):**
```json
{
  "success": true,
  "message": "Graph rebuild task has been submitted",
  "data": {
    "task_id": "asynq-task-uuid",
    "knowledge_base_id": "kb-00000001",
    "batch_size": 100
  }
}
```

**错误响应:**

- **400 Bad Request**: 图谱提取未启用
```json
{
  "error": "Knowledge base does not have graph extraction enabled",
  "code": "bad_request"
}
```

- **404 Not Found**: 知识库不存在
```json
{
  "error": "Knowledge base not found",
  "code": "not_found"
}
```

## 操作步骤

### 前提条件

1. **启用Neo4j**: 确保`.env`中配置了Neo4j
   ```env
   NEO4J_ENABLE=true
   NEO4J_URI=bolt://neo4j:7687
   NEO4J_USERNAME=neo4j
   NEO4J_PASSWORD=password
   ```

2. **启用知识库图谱提取**: 在知识库设置中启用图谱提取功能
   - 访问知识库设置页面
   - 开启"实体和关系提取"
   - 配置提取参数（标签、示例等）

### 典型使用场景

#### 场景1: 后期启用图谱功能

**问题**: 知识库已有大量文档，后来才决定启用图谱功能

**解决方案**:
```bash
# 1. 先在知识库设置中启用图谱提取
# 2. 调用批量重建API
curl -X POST "http://localhost:8080/api/v1/knowledge-bases/kb-00000001/rebuild-graph" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"batch_size": 0}'

# 3. 后续新上传的文档会自动提取图谱
```

#### 场景2: 更新图谱配置后重建

**问题**: 修改了关系类型定义，需要重新提取

**解决方案**:
```bash
# 1. 更新知识库的ExtractConfig配置
# 2. 重建图谱
curl -X POST "http://localhost:8080/api/v1/knowledge-bases/kb-00000001/rebuild-graph" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"batch_size": 200}'  # 分批处理避免内存占用过高
```

#### 场景3: 大规模知识库分批处理

**问题**: 知识库包含10000+文档，全量处理可能超时

**解决方案**:
```bash
# 使用较小的批次大小，多次调用
curl -X POST "http://localhost:8080/api/v1/knowledge-bases/kb-00000001/rebuild-graph" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"batch_size": 50}'  # 每批处理50个chunks
```

## 性能考虑

### 批次大小建议

| 知识库规模 | 建议batch_size | 预计处理时间 |
|-----------|---------------|------------|
| < 1000 chunks | 0 (全量) | 5-30分钟 |
| 1000-5000 chunks | 200 | 30分钟-2小时 |
| 5000-10000 chunks | 100 | 2-5小时 |
| > 10000 chunks | 50 | 5小时+ |

**注意**: 实际处理时间取决于：
- 模型响应速度
- Chunk内容复杂度
- 并发配置（GraphBuilder默认并发数=4）
- 服务器性能

### 资源占用

- **CPU**: GraphBuilder使用goroutine并发处理，默认并发数为4
- **内存**: 与batch_size相关，每批次会加载所有chunks到内存
- **网络**: 频繁调用LLM API，确保网络稳定
- **数据库**: 频繁写入Neo4j，确保Neo4j性能足够

### 优化建议

1. **非高峰期执行**: 图谱重建是CPU和IO密集型任务
2. **监控任务进度**: 查看应用日志观察处理进度
3. **分批处理大型库**: 避免单次任务运行时间过长
4. **调整并发配置**: 修改`graph.go`中的`MaxConcurrentEntityExtractions`

## 监控和日志

### 查看任务进度

任务提交后是异步执行，可通过日志监控：

```bash
# 查看应用日志
docker-compose logs -f app

# 关键日志示例
[INFO] Graph rebuild task submitted: task_id=xxx, kb_id=kb-00000001
[INFO] Processing graph rebuild task: kb_id=kb-00000001
[INFO] Found 500 chunks from 50 knowledge items to process
[INFO] Processing 500 chunks in 5 batches (batch_size=100)
[INFO] Processing batch 1/5 (100 chunks)
[INFO] Successfully processed batch 1/5
...
[INFO] Graph rebuild completed for kb xxx: processed 500 chunks in 15m30s
```

### 错误处理

批量重建过程中，单个批次失败不会中断整个任务：

```go
if err := builder.BuildGraph(ctx, batch); err != nil {
    logger.Errorf(ctx, "Failed to build graph for batch %d: %v", batchNum, err)
    // 继续处理下一批，不中断整个任务
    continue
}
```

**常见错误**:
- **LLM调用失败**: 检查模型配置和API可用性
- **Neo4j连接失败**: 检查Neo4j服务状态
- **内存不足**: 减小batch_size

## 常见问题 (FAQ)

### Q: 重建图谱会删除旧数据吗？
A: 是的，重建前会先删除知识库的所有旧图谱数据，然后重新构建。

### Q: 重建期间能否继续使用知识库？
A: 可以，但建议避免在重建期间修改知识库内容（上传/删除文档）。

### Q: 如何选择使用增量提取还是批量重建？
A: 
- **增量提取 (ChunkExtractService)**: 适合日常使用，文档上传后自动提取
- **批量重建 (GraphBuilder)**: 适合一次性重建、配置更新后重新提取

### Q: batch_size设置为0和设置为很大的数字有什么区别？
A: 
- `batch_size=0`: 全量处理，一次性处理所有chunks
- `batch_size=大数字`: 与全量处理类似，但有明确的上限

### Q: 为什么GraphBuilder没有被默认使用？
A: 
- ChunkExtractService更简单高效，适合增量场景
- GraphBuilder提供全局优化，但计算成本更高
- 两者各有优势，根据场景选择

### Q: 重建失败如何处理？
A: 
1. 检查日志找到失败原因
2. 修复问题后重新调用API
3. 旧图谱数据已删除，重建会从零开始

## 技术细节

### GraphBuilder vs ChunkExtractService

**GraphBuilder优势**:
- ✅ 两阶段提取更准确
- ✅ 全局权重计算（PMI算法）
- ✅ 实体度数统计
- ✅ Chunk关系网络构建

**ChunkExtractService优势**:
- ✅ 实时处理，无需等待
- ✅ 单次LLM调用，成本更低
- ✅ 逐chunk处理，内存占用小

### 配置关系

```yaml
# config.yaml

# ChunkExtractService使用 (增量式)
extract:
  extract_graph:
    description: "..."
    tags: [...]
    examples: [...]

# GraphBuilder使用 (批量式)
conversation:
  summary:
    extract_entities_prompt: "..."      # 实体提取提示词
    extract_relationships_prompt: "..." # 关系提取提示词
```

### 代码结构

```
internal/
├── types/
│   ├── extract_graph.go                    # TypeGraphRebuild任务类型
│   └── interfaces/
│       └── graph_rebuild.go                # GraphRebuildService接口
├── application/service/
│   ├── graph.go                            # GraphBuilder实现
│   └── graph_rebuild.go                    # 批量重建服务
├── handler/
│   └── knowledgebase.go                    # RebuildGraph API
├── router/
│   ├── router.go                           # 路由注册
│   └── task.go                             # 任务处理器注册
└── container/
    └── container.go                        # DI容器注册
```

## 总结

批量重建功能成功利用了现有的GraphBuilder实现，为后期启用图谱功能提供了完整的解决方案。通过异步任务队列处理大规模重建，支持分批处理和错误恢复，是对现有增量提取机制的有力补充。

**关键要点**:
1. ✅ 基于现有GraphBuilder，无需重复开发
2. ✅ 异步任务队列，支持大规模处理
3. ✅ 分批处理机制，灵活控制资源占用
4. ✅ 错误隔离，单批失败不影响整体
5. ✅ 完整日志，便于监控和排查问题
